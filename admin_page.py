import streamlit as st
import os
from langchain.document_loaders import PyPDFLoader, TextLoader, UnstructuredMarkdownLoader
from langchain.vectorstores import Chroma
from langchain.embeddings import OllamaEmbeddings

# Ollama é…ç½®
OLLAMA_BASE_URL = 'http://192.168.124.18:11434'  # Ollama çš„ IP å’Œç«¯å£
EMBEDDING_MODEL_NAME = 'mxbai-embed-large'  # åµŒå…¥æ¨¡å‹åç§°

# åˆå§‹åŒ– OllamaEmbeddings
EMBEDDINGS = OllamaEmbeddings(
    model=EMBEDDING_MODEL_NAME,
    base_url=OLLAMA_BASE_URL
)

# æŒä¹…åŒ–å­˜å‚¨ç›®å½•
PERSIST_DIRECTORY = 'db'

def admin_page():
    st.title('ğŸ“‚ ç®¡ç†å‘˜ç•Œé¢')
    st.write('åœ¨æ­¤é¡µé¢ä¸Šä¼ æˆ–åˆ é™¤çŸ¥è¯†åº“æ–‡ä»¶ã€‚')

    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    if not os.path.exists('documents'):
        os.makedirs('documents')

    # æ›´æ–°ä¸Šä¼ æ–‡ä»¶ç±»å‹ï¼Œæ”¯æŒ .md æ–‡ä»¶
    uploaded_files = st.file_uploader('é€‰æ‹© PDFã€TXT æˆ– MD æ–‡ä»¶ä¸Šä¼ ', type=['pdf', 'txt', 'md'], accept_multiple_files=True)

    if uploaded_files:
        for uploaded_file in uploaded_files:
            file_path = os.path.join('documents', uploaded_file.name)
            with open(file_path, 'wb') as f:
                f.write(uploaded_file.getbuffer())
            st.success(f'æ–‡ä»¶ {uploaded_file.name} ä¸Šä¼ æˆåŠŸï¼')
            # åŠ è½½å¹¶åµŒå…¥æ–‡ä»¶
            load_and_embed_file(file_path)
        st.info('æ‰€æœ‰æ–‡ä»¶å·²å¤„ç†å®Œæ¯•ã€‚')

    # æ˜¾ç¤ºå·²ä¸Šä¼ çš„æ–‡ä»¶
    st.subheader('å·²ä¸Šä¼ çš„æ–‡ä»¶')
    files = os.listdir('documents')
    if files:
        for file in files:
            st.write(file)
    else:
        st.write('æš‚æ— æ–‡ä»¶ã€‚')

    # åˆ é™¤æ–‡ä»¶
    delete_file = st.selectbox('é€‰æ‹©è¦åˆ é™¤çš„æ–‡ä»¶', [''] + files)
    if delete_file:
        if st.button('åˆ é™¤æ–‡ä»¶'):
            file_path = os.path.join('documents', delete_file)
            os.remove(file_path)
            # ä»å‘é‡æ•°æ®åº“ä¸­åˆ é™¤ç›¸åº”çš„åµŒå…¥
            delete_embeddings(delete_file)
            st.success(f'æ–‡ä»¶ {delete_file} å·²åˆ é™¤ï¼')

def load_and_embed_file(file_path):
    if file_path.endswith('.pdf'):
        loader = PyPDFLoader(file_path)
    elif file_path.endswith('.txt'):
        loader = TextLoader(file_path, encoding='utf-8')
    elif file_path.endswith('.md'):
        loader = UnstructuredMarkdownLoader(file_path)
    else:
        st.error('ä»…æ”¯æŒ PDFã€TXT å’Œ MD æ–‡ä»¶')
        return

    documents = loader.load()
    # åœ¨æ¯ä¸ªæ–‡æ¡£çš„å…ƒæ•°æ®ä¸­æ·»åŠ æ–‡ä»¶å
    for doc in documents:
        doc.metadata['source'] = os.path.basename(file_path)
    # å°†æ–‡æ¡£æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
    vectorstore = Chroma(
        persist_directory=PERSIST_DIRECTORY,
        embedding_function=EMBEDDINGS
    )
    vectorstore.add_documents(documents)
    # ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
    vectorstore.persist()

def delete_embeddings(delete_file):
    vectorstore = Chroma(
        persist_directory=PERSIST_DIRECTORY,
        embedding_function=EMBEDDINGS
    )
    # è·å–æ‰€æœ‰æ–‡æ¡£çš„å…ƒæ•°æ®å’Œ IDs
    docs = vectorstore._collection.get(include=['metadatas'])
    ids_to_delete = []
    for doc_id, metadata in zip(docs['ids'], docs['metadatas']):
        if metadata.get('source') == delete_file:
            ids_to_delete.append(doc_id)
    if ids_to_delete:
        vectorstore.delete(ids=ids_to_delete)
        # ä¿å­˜æ›´æ”¹
        vectorstore.persist()
